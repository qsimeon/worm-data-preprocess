{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from _main_utils import ROOT_DIR\n",
    "from preprocess.config import PREPROCESS_CONFIG\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "EXPERIMENT_DATASETS = PREPROCESS_CONFIG[\"EXPERIMENT_DATASETS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASETS\n",
      "[(0, 'Kato2015'), (1, 'Nichols2017'), (2, 'Skora2018'), (3, 'Kaplan2020'), (4, 'Nejatbakhsh2020'), (5, 'Yemini2021'), (6, 'Uzel2022'), (7, 'Dag2023'), (8, 'Leifer2023'), (9, 'Lin2023'), (10, 'Flavell2023'), (11, 'Venkatachalam2024')]\n"
     ]
    }
   ],
   "source": [
    "def load_dataset(name):\n",
    "    \"\"\"Load a specified neural dataset's pickle file by name\"\"\"\n",
    "    assert (name in EXPERIMENT_DATASETS), (\n",
    "        \"Unrecognized dataset!\"\n",
    "    )\n",
    "    file = os.path.join(ROOT_DIR, \"data\", \"processed\", \"neural\", f\"{name}.pickle\")\n",
    "    assert os.path.exists(file), f\"The file {file} does not exist.\"\n",
    "    with open(file, \"rb\") as pickle_in:\n",
    "        return pickle.load(pickle_in)\n",
    "\n",
    "ordered_datasets = [(i, name) for i, name in enumerate(EXPERIMENT_DATASETS)]\n",
    "print(f\"DATASETS\\n{ordered_datasets}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Datasets \n",
    "def helper(dataset_name: str):\n",
    "    \"\"\"Function we will call over and over again in this notebook\"\"\"\n",
    "    # load the dataset\n",
    "    print(f\"Loading {dataset_name}...\")\n",
    "    dataset = load_dataset(dataset_name)\n",
    "    print(len(dataset), dataset.keys(), end=\"\\n\\n\")\n",
    "\n",
    "    # number of ID'd neurons versus number of neurons measured\n",
    "    neurons_stats = dict(min=float(\"inf\"), max=float(\"-inf\"))\n",
    "    timesteps_stats = dict(min=float(\"inf\"), max=float(\"-inf\"))\n",
    "    total_avg, named_avg, neuron_to_slot_avg = 0, 0, 0\n",
    "    for worm in list(dataset.keys()):\n",
    "        single_worm_dataset = dataset[worm]\n",
    "        neuron_to_slot = len(single_worm_dataset[\"neuron_to_slot\"])\n",
    "        total_neurons = single_worm_dataset[\"num_neurons\"]\n",
    "        labeled_neurons = single_worm_dataset[\"num_labeled_neurons\"]\n",
    "        max_timesteps = single_worm_dataset[\"max_timesteps\"]\n",
    "        neuron_to_slot_avg += neuron_to_slot / len(dataset)\n",
    "        total_avg += total_neurons / len(dataset)\n",
    "        named_avg += labeled_neurons / len(dataset)\n",
    "        neurons_stats[\"min\"] = min(neurons_stats[\"min\"], labeled_neurons)\n",
    "        neurons_stats[\"max\"] = max(neurons_stats[\"max\"], labeled_neurons)\n",
    "        timesteps_stats[\"min\"] = min(timesteps_stats[\"min\"], max_timesteps)\n",
    "        timesteps_stats[\"max\"] = max(timesteps_stats[\"max\"], max_timesteps)\n",
    "    print(f\"Avg num. neuron ID'd/recorded : {int(named_avg)}/{int(total_avg)}\")\n",
    "    print(f\"Neuron_to_slot avg {int(neuron_to_slot_avg)}\")\n",
    "    print(f\"Range num. ID'd neurons : ({neurons_stats['min']}, {neurons_stats['max']})\")\n",
    "    print(\n",
    "        f\"Range len. calcium data : ({timesteps_stats['min']}, {timesteps_stats['max']})\"\n",
    "    )\n",
    "    print(f\"Avg num. ID'd : {int(named_avg)}/{int(total_avg)}\")\n",
    "    \n",
    "    # total_neurons_counted = sum(dataset[worm][\"num_neurons\"] for worm in dataset)\n",
    "    # print(f\"Total neurons counted in METHOD 1: {total_neurons_counted}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Flavell2023...\n",
      "40 dict_keys(['worm0', 'worm1', 'worm2', 'worm3', 'worm4', 'worm5', 'worm6', 'worm7', 'worm8', 'worm9', 'worm10', 'worm11', 'worm12', 'worm13', 'worm14', 'worm15', 'worm16', 'worm17', 'worm18', 'worm19', 'worm20', 'worm21', 'worm22', 'worm23', 'worm24', 'worm25', 'worm26', 'worm27', 'worm28', 'worm29', 'worm30', 'worm31', 'worm32', 'worm33', 'worm34', 'worm35', 'worm36', 'worm37', 'worm38', 'worm39'])\n",
      "\n",
      "Avg num. neuron ID'd/recorded : 88/136\n",
      "Neuron_to_slot avg 136\n",
      "Range num. ID'd neurons : (64, 115)\n",
      "Range len. calcium data : (2889, 2916)\n",
      "Avg num. ID'd : 88/136\n",
      "Total neurons counted in METHOD 1: 5458\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"Flavell2023\"\n",
    "dataset = helper(dataset_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "worm-preprocess",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
