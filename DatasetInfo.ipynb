{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from _main_utils import ROOT_DIR\n",
    "from preprocess.config import PREPROCESS_CONFIG\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "EXPERIMENT_DATASETS = PREPROCESS_CONFIG[\"EXPERIMENT_DATASETS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASETS\n",
      "[(0, 'Kato2015'), (1, 'Nichols2017'), (2, 'Skora2018'), (3, 'Kaplan2020'), (4, 'Nejatbakhsh2020'), (5, 'Yemini2021'), (6, 'Uzel2022'), (7, 'Dag2023'), (8, 'Leifer2023'), (9, 'Lin2023'), (10, 'Flavell2023'), (11, 'Venkatachalam2024')]\n"
     ]
    }
   ],
   "source": [
    "def load_dataset(name):\n",
    "    \"\"\"Load a specified neural dataset's pickle file by name\"\"\"\n",
    "    assert (name in EXPERIMENT_DATASETS), (\n",
    "        \"Unrecognized dataset!\"\n",
    "    )\n",
    "    file = os.path.join(ROOT_DIR, \"data\", \"processed\", \"neural\", f\"{name}.pickle\")\n",
    "    assert os.path.exists(file), f\"The file {file} does not exist.\"\n",
    "    with open(file, \"rb\") as pickle_in:\n",
    "        return pickle.load(pickle_in)\n",
    "\n",
    "ordered_datasets = [(i, name) for i, name in enumerate(EXPERIMENT_DATASETS)]\n",
    "print(f\"DATASETS\\n{ordered_datasets}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Datasets \n",
    "def helper(dataset_name: str):\n",
    "    \"\"\"Function we will call over and over again in this notebook\"\"\"\n",
    "    # load the dataset\n",
    "    print(f\"Loading {dataset_name}...\")\n",
    "    dataset = load_dataset(dataset_name)\n",
    "    print(len(dataset), dataset.keys(), end=\"\\n\\n\")\n",
    "\n",
    "    # number of ID'd neurons versus number of neurons measured\n",
    "    neurons_stats = dict(min=float(\"inf\"), max=float(\"-inf\"))\n",
    "    timesteps_stats = dict(min=float(\"inf\"), max=float(\"-inf\"))\n",
    "    total_avg, named_avg, neuron_to_slot_avg = 0, 0, 0\n",
    "    for worm in list(dataset.keys()):\n",
    "        num_worms = len(dataset)\n",
    "        single_worm_dataset = dataset[worm]\n",
    "        neuron_to_slot = len(single_worm_dataset[\"neuron_to_slot\"])\n",
    "        total_neurons = single_worm_dataset[\"num_neurons\"]\n",
    "        labeled_neurons = single_worm_dataset[\"num_labeled_neurons\"]\n",
    "        max_timesteps = single_worm_dataset[\"max_timesteps\"]\n",
    "        neuron_to_slot_avg += neuron_to_slot / num_worms\n",
    "        total_avg += total_neurons / num_worms\n",
    "        named_avg += labeled_neurons / num_worms\n",
    "        neurons_stats[\"min\"] = min(neurons_stats[\"min\"], labeled_neurons)\n",
    "        neurons_stats[\"max\"] = max(neurons_stats[\"max\"], labeled_neurons)\n",
    "        timesteps_stats[\"min\"] = min(timesteps_stats[\"min\"], max_timesteps)\n",
    "        timesteps_stats[\"max\"] = max(timesteps_stats[\"max\"], max_timesteps)\n",
    "        return (num_worms, total_avg, named_avg)\n",
    "    print(f\"Avg num. neuron ID'd/recorded : {int(named_avg)}/{int(total_avg)}\")\n",
    "    print(f\"Neuron_to_slot avg {int(neuron_to_slot_avg)}\")\n",
    "    print(f\"Range num. ID'd neurons : ({neurons_stats['min']}, {neurons_stats['max']})\")\n",
    "    print(\n",
    "        f\"Range len. calcium data : ({timesteps_stats['min']}, {timesteps_stats['max']})\"\n",
    "    )\n",
    "    print(f\"Avg num. ID'd : {int(named_avg)}/{int(total_avg)}\")\n",
    "    \n",
    "    total_neurons_counted = sum(dataset[worm][\"num_neurons\"] for worm in dataset)\n",
    "    print(f\"Total neurons counted in METHOD 1: {total_neurons_counted}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table from data_dict (before parquet generation)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Num Worms</th>\n",
       "      <th>(Named Avg, Total Avg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kato2015</td>\n",
       "      <td>12</td>\n",
       "      <td>(42, 128)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nichols2017</td>\n",
       "      <td>44</td>\n",
       "      <td>(35, 108)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Skora2018</td>\n",
       "      <td>12</td>\n",
       "      <td>(47, 129)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kaplan2020</td>\n",
       "      <td>19</td>\n",
       "      <td>(37, 115)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nejatbakhsh2020</td>\n",
       "      <td>21</td>\n",
       "      <td>(174, 175)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Yemini2021</td>\n",
       "      <td>49</td>\n",
       "      <td>(111, 126)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Uzel2022</td>\n",
       "      <td>6</td>\n",
       "      <td>(50, 139)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dag2023</td>\n",
       "      <td>7</td>\n",
       "      <td>(101, 143)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Leifer2023</td>\n",
       "      <td>110</td>\n",
       "      <td>(64, 68)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lin2023</td>\n",
       "      <td>577</td>\n",
       "      <td>(8, 8)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Flavell2023</td>\n",
       "      <td>40</td>\n",
       "      <td>(89, 136)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Venkatachalam2024</td>\n",
       "      <td>22</td>\n",
       "      <td>(187, 187)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Dataset  Num Worms (Named Avg, Total Avg)\n",
       "0            Kato2015         12              (42, 128)\n",
       "1         Nichols2017         44              (35, 108)\n",
       "2           Skora2018         12              (47, 129)\n",
       "3          Kaplan2020         19              (37, 115)\n",
       "4     Nejatbakhsh2020         21             (174, 175)\n",
       "5          Yemini2021         49             (111, 126)\n",
       "6            Uzel2022          6              (50, 139)\n",
       "7             Dag2023          7             (101, 143)\n",
       "8          Leifer2023        110               (64, 68)\n",
       "9             Lin2023        577                 (8, 8)\n",
       "10        Flavell2023         40              (89, 136)\n",
       "11  Venkatachalam2024         22             (187, 187)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a table for all datasets\n",
    "results = []\n",
    "\n",
    "for dataset_name in EXPERIMENT_DATASETS:\n",
    "    dataset = load_dataset(dataset_name)\n",
    "    num_worms = len(dataset)\n",
    "    \n",
    "    # Calculate statistics\n",
    "    total_avg, named_avg = 0, 0\n",
    "    for worm in dataset:\n",
    "        single_worm_dataset = dataset[worm]\n",
    "        total_neurons = single_worm_dataset[\"num_neurons\"]\n",
    "        labeled_neurons = single_worm_dataset[\"num_labeled_neurons\"]\n",
    "        total_avg += total_neurons / num_worms\n",
    "        named_avg += labeled_neurons / num_worms\n",
    "    \n",
    "    results.append({\n",
    "        'Dataset': dataset_name,\n",
    "        'Num Worms': num_worms,\n",
    "        'Named Avg': round(named_avg),\n",
    "        'Total Avg': round(total_avg)\n",
    "    })\n",
    "\n",
    "print(\"Table from data_dict (before parquet generation)\")\n",
    "# note that in the parquet generation some all_zero calcium traces are removed\n",
    "# in testing this only applied to Yemini2021 -- otherwise data_dict and parquet\n",
    "# dataset info should be indentical \n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df['(Named Avg, Total Avg)'] = df.apply(lambda x: f\"({x['Named Avg']}, {x['Total Avg']})\", axis=1)\n",
    "df = df[['Dataset', 'Num Worms', '(Named Avg, Total Avg)']]\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "worm-preprocess",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
